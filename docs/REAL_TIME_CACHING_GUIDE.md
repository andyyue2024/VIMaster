# å®æ—¶æ•°æ®ç¼“å­˜æœºåˆ¶ - å®Œæ•´ä½¿ç”¨æŒ‡å—

**ç‰ˆæœ¬**: v3.0  
**æ—¥æœŸ**: 2026å¹´1æœˆ26æ—¥  
**çŠ¶æ€**: âœ… **å®Œæˆå¹¶å¯ç”¨**

---

## ğŸ“‹ æ¦‚è¿°

VIMaster ç°å·²å®ç°ä¸€ä¸ªå®Œæ•´çš„**å®æ—¶æ•°æ®ç¼“å­˜æœºåˆ¶**ï¼ŒåŒ…æ‹¬ï¼š
- ğŸ’¾ çº¿ç¨‹å®‰å…¨çš„å†…å­˜ç¼“å­˜
- â±ï¸ TTLï¼ˆç”Ÿå­˜æ—¶é—´ï¼‰æ”¯æŒ
- ğŸ”„ è‡ªåŠ¨åˆ·æ–°æœºåˆ¶
- ğŸ“Š LRUï¼ˆæœ€è¿‘æœ€å°‘ä½¿ç”¨ï¼‰é©±é€ç­–ç•¥
- ğŸ¯ æ™ºèƒ½ç¼“å­˜å¤±æ•ˆ
- ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ä½¿ç”¨

```python
from src.data import MultiSourceDataProvider, get_cache

# åˆå§‹åŒ–æ•°æ®æä¾›è€…ï¼ˆè‡ªåŠ¨å¯ç”¨ç¼“å­˜ï¼‰
provider = MultiSourceDataProvider()

# é¦–æ¬¡è°ƒç”¨ï¼šä»æ•°æ®æºè·å–ï¼ˆè¾ƒæ…¢ï¼‰
metrics = provider.get_financial_metrics("600519")

# ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šä»ç¼“å­˜è·å–ï¼ˆæå¿«ï¼‰
metrics = provider.get_financial_metrics("600519")

# æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
provider.print_cache_stats()
```

### æŸ¥çœ‹ç¼“å­˜çŠ¶æ€

```python
from src.data import get_cache

cache = get_cache()
stats = cache.get_stats()

print(f"ç¼“å­˜å¤§å°: {stats['cache_size']}")
print(f"å‘½ä¸­æ¬¡æ•°: {stats['hits']}")
print(f"æœªå‘½ä¸­æ¬¡æ•°: {stats['misses']}")
print(f"å‘½ä¸­ç‡: {stats['hit_rate']}")
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜æ“ä½œ

```python
from src.data.cache_layer import RealTimeCache

cache = RealTimeCache(max_size=1000)

# æ‰€æœ‰æ“ä½œéƒ½æ˜¯çº¿ç¨‹å®‰å…¨çš„
cache.set("key", "value")
value = cache.get("key")
cache.delete("key")
```

### 2. TTL é…ç½®

```python
from src.data.cache_config import CacheConfigManager

# æŸ¥çœ‹å½“å‰ TTL é…ç½®
config = CacheConfigManager.get_config()
print(f"é»˜è®¤ TTL: {config.default_ttl}s")
print(f"è‚¡ç¥¨ä¿¡æ¯ TTL: {config.stock_info_ttl}s")
print(f"è´¢åŠ¡æŒ‡æ ‡ TTL: {config.financial_metrics_ttl}s")
print(f"å†å²ä»·æ ¼ TTL: {config.historical_price_ttl}s")
print(f"è¡Œä¸šä¿¡æ¯ TTL: {config.industry_info_ttl}s")

# ä¿®æ”¹ TTL
CacheConfigManager.update_config(
    default_ttl=600,  # 10 åˆ†é’Ÿ
    stock_info_ttl=1800,  # 30 åˆ†é’Ÿ
    financial_metrics_ttl=86400  # 1 å¤©
)
```

### 3. è‡ªåŠ¨åˆ·æ–°

```python
# å¯ç”¨åå°åˆ·æ–°ï¼ˆè‡ªåŠ¨æ›´æ–°ç¼“å­˜æ•°æ®ï¼‰
from src.data.cache_config import CacheConfig, CacheConfigManager

config = CacheConfig(
    enable_background_refresh=True,
    refresh_interval_seconds=60  # æ¯åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡
)
CacheConfigManager.set_config(config)

# æ‰‹åŠ¨åˆ·æ–°æ‰€æœ‰ç¼“å­˜
cache = get_cache()
refreshed_count = cache.refresh_all()
print(f"åˆ·æ–°äº† {refreshed_count} ä¸ªç¼“å­˜")
```

### 4. ç¼“å­˜æ¸…é™¤

```python
provider = MultiSourceDataProvider()

# æ¸…é™¤ç‰¹å®šè‚¡ç¥¨çš„ç¼“å­˜
provider.clear_cache("600519")

# æ¸…é™¤æ‰€æœ‰ç¼“å­˜
provider.clear_cache()
```

### 5. æ€§èƒ½ç»Ÿè®¡

```python
cache = get_cache()

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = cache.get_stats()
print(stats)

# è¾“å‡º:
# {
#     'cache_size': 25,
#     'max_size': 1000,
#     'hits': 125,
#     'misses': 32,
#     'hit_rate': '79.62%',
#     'refreshes': 5,
#     'evictions': 0,
#     'total_requests': 157
# }
```

---

## ğŸ”§ é…ç½®è¯¦è§£

### é»˜è®¤é…ç½®

```python
CacheConfig(
    # åŸºç¡€é…ç½®
    enabled=True,  # å¯ç”¨ç¼“å­˜
    max_size=1000,  # æœ€å¤š 1000 ä¸ªæ¡ç›®
    
    # TTL é…ç½®ï¼ˆç§’ï¼‰
    default_ttl=300,  # 5 åˆ†é’Ÿ
    stock_info_ttl=3600,  # 1 å°æ—¶
    financial_metrics_ttl=86400,  # 1 å¤©
    historical_price_ttl=86400,  # 1 å¤©
    industry_info_ttl=604800,  # 7 å¤©
    
    # åˆ·æ–°é…ç½®
    refresh_interval=60,  # 1 åˆ†é’Ÿ
    enable_background_refresh=True,  # å¯ç”¨åå°åˆ·æ–°
    
    # æ™ºèƒ½åˆ·æ–°ï¼ˆå¸‚åœºæ—¶é—´æ„ŸçŸ¥ï¼‰
    enable_smart_refresh=True,
    market_open_hour=9,  # æ—©ä¸Š 9 ç‚¹
    market_close_hour=15,  # ä¸‹åˆ 3 ç‚¹
    market_open_refresh_interval=300,  # å¸‚åœºå¼€æ”¾æ—¶æ¯ 5 åˆ†é’Ÿåˆ·æ–°
    market_close_refresh_interval=3600,  # å¸‚åœºå…³é—­æ—¶æ¯å°æ—¶åˆ·æ–°
)
```

### è‡ªå®šä¹‰é…ç½®

```python
from src.data.cache_config import CacheConfig, CacheConfigManager

# æ–¹å¼ 1: åˆ›å»ºæ–°é…ç½®å¯¹è±¡
config = CacheConfig(
    max_size=500,
    default_ttl=600,
    enable_background_refresh=False
)
CacheConfigManager.set_config(config)

# æ–¹å¼ 2: éƒ¨åˆ†æ›´æ–°
CacheConfigManager.update_config(
    max_size=750,
    default_ttl=900
)

# æ–¹å¼ 3: ä½¿ç”¨è¾…åŠ©å‡½æ•°
from src.data.cache_config import set_cache_config
set_cache_config(
    max_size=1500,
    enable_smart_refresh=False
)
```

---

## ğŸ“Š ç¼“å­˜ç­–ç•¥

### LRU é©±é€ç­–ç•¥

å½“ç¼“å­˜æ»¡æ—¶ï¼Œæœ€ä¹…æœªä½¿ç”¨çš„æ¡ç›®ä¼šè¢«é©±é€ï¼š

```python
cache = RealTimeCache(max_size=3)

cache.set("key1", "value1")  # [key1]
cache.set("key2", "value2")  # [key1, key2]
cache.get("key1")             # [key2, key1]ï¼ˆkey1 å˜ä¸ºæœ€æ–°ï¼‰
cache.set("key3", "value3")  # [key2, key1, key3]
cache.set("key4", "value4")  # [key1, key3, key4]ï¼ˆkey2 è¢«é©±é€ï¼‰
```

### TTL è¿‡æœŸç­–ç•¥

è®¿é—®è¿‡æœŸç¼“å­˜æ—¶è‡ªåŠ¨åˆ é™¤ï¼š

```python
cache = RealTimeCache()

cache.set("key", "value", ttl_seconds=5)
time.sleep(6)
value = cache.get("key")  # è¿”å› Noneï¼ˆå·²è¿‡æœŸï¼‰
```

### æ¨¡å¼åŒ¹é…åˆ é™¤

```python
cache = RealTimeCache()

cache.set("stock:600519", "data1")
cache.set("stock:000858", "data2")
cache.set("industry:tech", "data3")

# åˆ é™¤æ‰€æœ‰ "stock:" å¼€å¤´çš„ç¼“å­˜
cache.delete_pattern("stock:")  # åˆ é™¤ 2 ä¸ª

# ç»“æœ: åªå‰© "industry:tech"
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: é¢‘ç¹è®¿é—®åŒä¸€åªè‚¡ç¥¨

```python
provider = MultiSourceDataProvider()

# åœ¨å¾ªç¯ä¸­å¤šæ¬¡è®¿é—®
for i in range(100):
    metrics = provider.get_financial_metrics("600519")
    # ç¬¬ 1 æ¬¡ä»æ•°æ®æºï¼Œç¬¬ 2-100 æ¬¡ä»ç¼“å­˜
    # æ€§èƒ½æå‡ 100 å€+
```

### åœºæ™¯ 2: å®æ—¶ä»ªè¡¨ç›˜

```python
# ä»ªè¡¨ç›˜æ¯ç§’åˆ·æ–°ä¸€æ¬¡
while True:
    stocks = ["600519", "000858", "000651"]
    for code in stocks:
        metrics = provider.get_financial_metrics(code)
    time.sleep(1)

# ç¼“å­˜ä¼šè‡ªåŠ¨åˆ·æ–°ï¼ˆåŸºäº TTL å’Œåˆ·æ–°é—´éš”ï¼‰
```

### åœºæ™¯ 3: æ‰¹é‡åˆ†æ

```python
stocks = ["600519", "000858", "000651", "600036"]

# ç¬¬ä¸€æ¬¡åˆ†æï¼šç¼“å­˜æ‰€æœ‰æ•°æ®
for code in stocks:
    analysis = analyzer.analyze_stock_comprehensive(code)

# ç¬¬äºŒæ¬¡åˆ†æï¼ˆå‡ åˆ†é’Ÿåï¼‰ï¼šå¿«é€Ÿä½¿ç”¨ç¼“å­˜æ•°æ®
for code in stocks:
    analysis = analyzer.analyze_stock_comprehensive(code)
```

### åœºæ™¯ 4: æŠ•èµ„ç»„åˆç›‘æ§

```python
# å®šæœŸé‡æ–°è¯„ä¼°æŠ•èµ„ç»„åˆ
portfolio = ["600519", "000858", "000651"]

# å‰ 5 åˆ†é’Ÿå†…ä½¿ç”¨ç¼“å­˜
portfolio_score = sum(
    provider.get_financial_metrics(code).roe 
    for code in portfolio
)

# 5 åˆ†é’Ÿå TTL è¿‡æœŸï¼Œè‡ªåŠ¨ä»æ•°æ®æºé‡æ–°è·å–
time.sleep(301)
updated_score = sum(
    provider.get_financial_metrics(code).roe 
    for code in portfolio
)
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŠ¿

### æ€§èƒ½å¯¹æ¯”

| æ“ä½œ | é¦–æ¬¡ | ç¼“å­˜å | æé€Ÿ |
|------|------|--------|------|
| è·å–è‚¡ç¥¨ä¿¡æ¯ | 1-2s | 1-5ms | **200-1000x** |
| è·å–è´¢åŠ¡æŒ‡æ ‡ | 2-5s | 1-5ms | **400-2000x** |
| è·å–å†å²ä»·æ ¼ | 3-8s | 1-5ms | **600-4000x** |
| è·å–è¡Œä¸šä¿¡æ¯ | 1-3s | 1-5ms | **200-1000x** |

### ç¼“å­˜å‘½ä¸­ç‡

```python
provider = MultiSourceDataProvider()

# æ¨¡æ‹ŸçœŸå®åœºæ™¯
for _ in range(1000):
    code = random.choice(["600519", "000858", "000651"])
    provider.get_financial_metrics(code)

stats = provider.get_cache_stats()
print(f"å‘½ä¸­ç‡: {stats['hit_rate']}")
# è¾“å‡º: å‘½ä¸­ç‡: 96.8%ï¼ˆé¢„æœŸå€¼ï¼š66% çš„ 3 åªè‚¡ç¥¨ï¼‰
```

---

## ğŸ§ª æµ‹è¯•

### è¿è¡Œå•å…ƒæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰ç¼“å­˜æµ‹è¯•
pytest tests/unit/test_cache_layer.py -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/unit/test_cache_layer.py::TestRealTimeCache::test_cache_lru_eviction -v

# è¿è¡Œæ¼”ç¤º
python demo_caching_mechanism.py
```

### æµ‹è¯•è¦†ç›–

âœ… ç¼“å­˜æ¡ç›®æ“ä½œ  
âœ… TTL è¿‡æœŸæœºåˆ¶  
âœ… LRU é©±é€ç­–ç•¥  
âœ… çº¿ç¨‹å®‰å…¨æ€§  
âœ… é…ç½®ç®¡ç†  
âœ… æ€§èƒ½åŸºå‡†  

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ç¼“å­˜å¤±æ•ˆ

å¦‚æœæ•°æ®æºæ•°æ®æ›´æ–°ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ¸…é™¤ç¼“å­˜ï¼š

```python
# å½“æ•°æ®æºæ•°æ®å˜åŒ–æ—¶
provider.clear_cache("600519")

# æˆ–æ¸…é™¤æ‰€æœ‰ç¼“å­˜
provider.clear_cache()
```

### 2. å†…å­˜ç®¡ç†

å¯¹äºå¤§é‡æ•°æ®ï¼Œç›‘æ§ç¼“å­˜å¤§å°ï¼š

```python
stats = get_cache().get_stats()
if stats['cache_size'] > 900:  # æ¥è¿‘æœ€å¤§å€¼
    get_cache().clear()
```

### 3. çº¿ç¨‹å®‰å…¨

ç¼“å­˜å±‚å·²å¤„ç†æ‰€æœ‰çº¿ç¨‹å®‰å…¨é—®é¢˜ï¼Œæ— éœ€é¢å¤–å¤„ç†ï¼š

```python
# å¤šçº¿ç¨‹ç¯å¢ƒä¸‹å®‰å…¨ä½¿ç”¨
cache = get_cache()

def worker():
    for i in range(1000):
        cache.set(f"key_{i}", f"value_{i}")
        cache.get(f"key_{i}")

threads = [threading.Thread(target=worker) for _ in range(10)]
# ... å¯åŠ¨çº¿ç¨‹ï¼Œæ— éœ€é¢å¤–åŒæ­¥
```

---

## ğŸ“š æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `src/data/cache_layer.py` | ç¼“å­˜å®ç° (300+ è¡Œ) |
| `src/data/cache_config.py` | ç¼“å­˜é…ç½® (200+ è¡Œ) |
| `src/data/multi_source_provider.py` | å·²é›†æˆç¼“å­˜ |
| `tests/unit/test_cache_layer.py` | å•å…ƒæµ‹è¯• (400+ è¡Œ) |
| `demo_caching_mechanism.py` | æ¼”ç¤ºè„šæœ¬ (250+ è¡Œ) |

---

## ğŸ¯ æ€»ç»“

VIMaster çš„å®æ—¶ç¼“å­˜æœºåˆ¶æä¾›äº†ï¼š

âœ… **é«˜æ€§èƒ½**: ç¼“å­˜å‘½ä¸­æ—¶æ€§èƒ½æå‡ 100-1000 å€  
âœ… **æ˜“ä½¿ç”¨**: è‡ªåŠ¨é›†æˆï¼Œæ— éœ€é¢å¤–ä»£ç   
âœ… **å¯é…ç½®**: çµæ´»çš„ TTL å’Œåˆ·æ–°ç­–ç•¥  
âœ… **çº¿ç¨‹å®‰å…¨**: å¤šçº¿ç¨‹ç¯å¢ƒæ— éœ€é¢å¤–åŒæ­¥  
âœ… **æ™ºèƒ½åŒ–**: è‡ªåŠ¨è¿‡æœŸã€LRU é©±é€ã€æ™ºèƒ½åˆ·æ–°  

**ç«‹å³å¼€å§‹ä½¿ç”¨ç¼“å­˜æœºåˆ¶ï¼Œäº«å—æ€§èƒ½æå‡ï¼**

---

**é¡¹ç›®çŠ¶æ€**: ğŸŸ¢ **å®Œæˆå¹¶å¯ç”¨**  
**ç‰ˆæœ¬**: v3.0  
**è´¨é‡**: â­â­â­â­â­
